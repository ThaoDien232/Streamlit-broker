import os
import json
import requests
import streamlit as st
from datetime import datetime, time
from dotenv import load_dotenv

# Load API key from .env
load_dotenv()
API_KEY = os.getenv("SONAR_API_KEY")
API_URL = "https://api.perplexity.ai/chat/completions"

# Trusted Vietnamese finance news sites
VN_SOURCES = [
    "vietstock.vn",
    "cafef.vn",
    "vnexpress.net",
    "ndh.vn",
    "vneconomy.vn",
    "nhipcaudautu.vn"
]

# ------------- Helper Functions ------------------

def fetch_news(tickers, domains=VN_SOURCES, recency="day", context_size="medium"):
    """Call Perplexity Sonar API and fetch Vietnamese news summaries about tickers."""
    if not API_KEY:
        st.error("‚ùå Missing SONAR_API_KEY. Please add it to your .env file.")
        return None, None, []

    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }

    # Build enhanced search terms with both tickers and company names
    enhanced_search_terms = []
    for ticker in tickers:
        search_terms = get_search_terms(ticker)
        enhanced_search_terms.append(search_terms)
    
    # Build user prompt based on recency period
    if recency == "day":
        time_period = "2 ng√†y g·∫ßn nh·∫•t"
        prompt = (
            f"T√¨m T·∫§T C·∫¢ tin t·ª©c v·ªÅ c√°c c√¥ng ty sau trong {time_period}: {', '.join(enhanced_search_terms)}. "
            f"T√¨m ki·∫øm c·∫£ M√É C·ªî PHI·∫æU v√† T√äN C√îNG TY ƒë·ªÉ c√≥ k·∫øt qu·∫£ ch√≠nh x√°c nh·∫•t. "
            f"CH·ªà b√°o c√°o tin t·ª©c c√≥ ch·ª©a t√™n m√£ c·ªï phi·∫øu ho·∫∑c t√™n c√¥ng ty c·ª• th·ªÉ. KH√îNG b√°o c√°o tin t·ª©c chung v·ªÅ th·ªã tr∆∞·ªùng."
            f"N·∫øu kh√¥ng t√¨m th·∫•y tin t·ª©c v·ªÅ c√¥ng ty n√†o, b·ªè qua c√¥ng ty ƒë√≥."
            f"ƒê·ªãnh d·∫°ng: M·ªói tin t·ª©c l√† M·ªòT D√íNG RI√äNG, b·∫Øt ƒë·∫ßu b·∫±ng **M√É C·ªî PHI·∫æU**: theo sau l√† n·ªôi dung v√† ngu·ªìn."
            f"T·∫≠p trung v√†o: k·∫øt qu·∫£ kinh doanh, thay ƒë·ªïi nh√¢n s·ª±, k·∫ø ho·∫°ch tƒÉng v·ªën, th√¥ng b√°o quan tr·ªçng. "
            f"Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."
        )
    else:  # week or other periods
        time_period = "2 tu·∫ßn g·∫ßn nh·∫•t" if recency == "week" else "th·ªùi gian g·∫ßn ƒë√¢y"
        prompt = (
            f"T√¨m T·∫§T C·∫¢ tin t·ª©c v·ªÅ c√°c c√¥ng ty sau trong {time_period}: {', '.join(enhanced_search_terms)}. "
            f"T√¨m ki·∫øm c·∫£ M√É C·ªî PHI·∫æU v√† T√äN C√îNG TY ƒë·ªÉ c√≥ k·∫øt qu·∫£ ch√≠nh x√°c nh·∫•t. "
            f"CH·ªà b√°o c√°o tin t·ª©c c√≥ ch·ª©a t√™n m√£ c·ªï phi·∫øu ho·∫∑c t√™n c√¥ng ty c·ª• th·ªÉ. KH√îNG b√°o c√°o tin t·ª©c chung v·ªÅ th·ªã tr∆∞·ªùng."
            f"ƒê·ªãnh d·∫°ng: **M√É C·ªî PHI·∫æU**: [N·ªôi dung tin t·ª©c] - [Ngu·ªìn] "
            f"T·∫≠p trung v√†o: k·∫øt qu·∫£ kinh doanh, thay ƒë·ªïi nh√¢n s·ª±, k·∫ø ho·∫°ch m·ªõi, bi·∫øn ƒë·ªông gi√°, tin ng√†nh. "
            f"Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."
        )

    # Add date-based seed for consistency within the same day
    import hashlib
    from datetime import datetime
    
    current_date_str = datetime.now().strftime("%Y-%m-%d")
    tickers_str = ",".join(sorted(tickers))  # Sort for consistency
    seed_string = f"{current_date_str}-{tickers_str}-{recency}"
    seed_hash = int(hashlib.md5(seed_string.encode()).hexdigest()[:8], 16) % 1000
    
    payload = {
        "model": "sonar-pro",
        "messages": [
            {"role": "system", "content": "B·∫°n l√† ph√≥ng vi√™n t√†i ch√≠nh chuy√™n nghi·ªáp. H√£y t√¨m v√† tr·∫£ v·ªÅ c√°c tin t·ª©c m·ªôt c√°ch NH·∫§T QU√ÅN. Lu√¥n ghi r√µ m√£ c·ªï phi·∫øu ·ªü ƒë·∫ßu m·ªói tin t·ª©c v√† ng√†y ƒëƒÉng b√†i b√°o ·ªü cu·ªëi m·ªói tin t·ª©c n·∫øu c√≥. Tr·∫£ v·ªÅ k·∫øt qu·∫£ ·ªïn ƒë·ªãnh v√† ƒë√°ng tin c·∫≠y."},
            {"role": "user", "content": prompt}
        ],
        "search_recency_filter": recency,  # "day", "week", "month"
        "search_domain_filter": domains,   # restrict to VN finance websites
        "web_search_options": {"search_context_size": "high"},  # Increased for more comprehensive results
        "return_related_questions": False,
        "temperature": 0.1  # Lower temperature for more consistent results
    }

    try:
        resp = requests.post(API_URL, headers=headers, json=payload, timeout=120)
        resp.raise_for_status()
        data = resp.json()

        summary = data["choices"][0]["message"]["content"]
        sources = data.get("search_results", [])
        
        # Simpler filtering - only remove obvious "no news" lines, keep more content
        lines = summary.split('\n')
        filtered_lines = []
        found_tickers = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Only skip very specific "no news" patterns
            skip_patterns = [
                "kh√¥ng c√≥ tin t·ª©c c·ª• th·ªÉ v·ªÅ c√°c m√£ c·ªï phi·∫øu",
                "kh√¥ng t√¨m th·∫•y tin t·ª©c n√†o v·ªÅ",
                "kh√¥ng c√≥ th√¥ng tin m·ªõi v·ªÅ"
            ]
            
            should_skip = any(pattern.lower() in line.lower() for pattern in skip_patterns)
            
            if not should_skip:
                # Display each line directly to the app
                st.write(line)
                filtered_lines.append(line)
                # Check for ticker mentions
                for ticker in tickers:
                    if ticker.upper() in line.upper() and ticker not in found_tickers:
                        found_tickers.append(ticker)
        
        # Simple filtering - keep most content, minimal processing
        filtered_summary = '\n'.join(filtered_lines) if filtered_lines else "Kh√¥ng c√≥ tin t·ª©c m·ªõi trong kho·∫£ng th·ªùi gian ƒë∆∞·ª£c y√™u c·∫ßu."
        
        # Ensure each ticker starts on a new line
        formatted_summary = filtered_summary
        for ticker in tickers:
            # Replace pattern where ticker appears after other content on same line
            formatted_summary = formatted_summary.replace(f' {ticker}:', f'\n\n**{ticker}**:')
            formatted_summary = formatted_summary.replace(f' **{ticker}**:', f'\n\n**{ticker}**:')
        
        # Clean up any double line breaks at the beginning
        formatted_summary = formatted_summary.strip()
        
        return formatted_summary, sources, found_tickers
    except Exception as e:
        st.error(f"API error: {e}")
        return None, None, []

# Priority tickers for brokerage and banking industry (in priority order)
PRIORITY_TICKERS = ["SSI", "VND", "VCI", "HCM", "VIX", "SHS"]
OTHER_TICKERS = ["BSI", "FTS", "VIG", "CTS", "TCB", "VCB", "BID", "CTG", "MBB", "VPB", 
                 "TPB", "STB", "ACB", "HDB", "MSB", "EIB", "VIB", "SHB", "OCB", "LPB", "NAB", "KLB", "BVB"]
ALL_PREDEFINED_TICKERS = PRIORITY_TICKERS + OTHER_TICKERS

# Ticker to Company Name Mapping for Enhanced Search Accuracy
TICKER_TO_COMPANY = {
    # Priority Brokerage Companies
    "SSI": "SSI",
    "VND": "VNDirect", 
    "VCI": "Vietcap",
    "HCM": "HSC",
    "VIX": "VIX Securities",
    "SHS": "Saigon Hanoi Securities",
    "IPA": "I.P.A",
    
    # Other Brokerage Companies
    "BSI": "BSI",
    "FTS": "Ch·ª©ng kho√°n FPT", 
    "CTS": "Ch·ª©ng kho√°n C√¥ng Th∆∞∆°ng",
    
    # Major Banks
    "TCB": "Techcombank",
    "VCB": "Vietcombank", 
    "BID": "BIDV",
    "CTG": "Vietinbank",
    "MBB": "Ng√¢n h√†ng Qu√¢n ƒê·ªôi",
    "VPB": "VPBank",
    "TPB": "Ng√¢n h√†ng Ti√™n Phong",
    "STB": "Sacombank",
    "ACB": "Ng√¢n h√†ng √Å Ch√¢u",
    "HDB": "HDBank",
    "MSB": "Ng√¢n h√†ng Maritime",
    "EIB": "Eximbank",
    "VIB": "VIB Bank",
    "SHB": "SHB Bank", 
    "OCB": "Ng√¢n h√†ng Ph∆∞∆°ng ƒê√¥ng",
    "LPB": "Ng√¢n h√†ng L·ªôc Ph√°t",
    "NAB": "Nam √Å",
    "KLB": "Ng√¢n h√†ng Ki√™n Long",
    "BVB": "Ng√¢n h√†ng B·∫£o Vi·ªát"
}

def get_search_terms(ticker):
    """Get both ticker and company name for enhanced search accuracy."""
    company_name = TICKER_TO_COMPANY.get(ticker, "")
    if company_name:
        return f"{ticker} OR {company_name}"
    return ticker

# ------------- Streamlit UI ------------------

st.set_page_config(page_title="üì∞ Vietnam Finance News Reporter", layout="wide")
st.title("üì∞ News Reporter")

# Initialize session state for news
if 'banking_news_loaded' not in st.session_state:
    st.session_state.banking_news_loaded = False
if 'banking_summary' not in st.session_state:
    st.session_state.banking_summary = None
if 'banking_sources' not in st.session_state:
    st.session_state.banking_sources = None
if 'banking_found_tickers' not in st.session_state:
    st.session_state.banking_found_tickers = []
if 'last_news_date' not in st.session_state:
    st.session_state.last_news_date = None

# Brokerage & Banking News Alert (moved to top)
st.subheader("üè¶ Brokerage & Banking News Alert")

# Manual refresh button only
col1, col2 = st.columns([1, 4])
with col1:
    load_banking_news = st.button("üì∞ Load Latest News")

if load_banking_news:
    with st.spinner("Fetching all news from the last 2 days..."):
        # Always get fresh results from last 2 days (no caching, no session state dependency)
        predefined_summary, predefined_sources, found_tickers = fetch_news(ALL_PREDEFINED_TICKERS, recency="day")
    
    # Store in session state
    st.session_state.banking_summary = predefined_summary
    st.session_state.banking_sources = predefined_sources
    st.session_state.banking_found_tickers = found_tickers
    st.session_state.banking_news_loaded = True

# Always display news if available
if st.session_state.banking_summary:
    with st.container():
        found_tickers_str = ", ".join(st.session_state.banking_found_tickers) if st.session_state.banking_found_tickers else "kh√¥ng x√°c ƒë·ªãnh"
        st.success(f"‚úÖ Latest news for brokerage and banking stocks (Found: {found_tickers_str}):")
        # News is already displayed directly in fetch_news() function
        
        if st.session_state.banking_sources:
            with st.expander("üìã Detailed Sources"):
                for s in st.session_state.banking_sources:
                    title = s.get("title", "(no title)")
                    url = s.get("url", "#")
                    date = s.get("date", "")
                    st.markdown(f"- [{title}]({url}) ({date})")
        
elif st.session_state.banking_news_loaded:
    st.info("‚ÑπÔ∏è No banking/brokerage news found in the last 2 days.")
else:
    st.info("üí° Click 'Load Latest News' to fetch the latest news from the past 2 days.")

st.divider()
st.subheader("üîç Company News Search")

tickers = st.text_input("Enter tickers:", "")
tickers_list = [t.strip().upper() for t in tickers.split(",") if t.strip()]

col1, col2 = st.columns([1,1])
with col1:
    refresh = st.button("üîÑ Refresh News")

with col2:
    st.caption("‚è∞ The app will automatically refresh at **10:00 AM** every day.")

# Remove caching to ensure fresh results every time
# @st.cache_data(ttl=60*60)  # cache 1 hour - DISABLED for consistency
def get_fresh_news(tickers):
    return fetch_news(tickers)

# Custom ticker news search (only show when user enters tickers)
if tickers_list:
    # Always get fresh news for custom tickers using 2-week period
    summary, sources, found_tickers = fetch_news(tickers_list, recency="week")

    # Display custom ticker news results
    if summary:
        st.subheader("üì∞ Custom Ticker News")
        if found_tickers:
            st.success(f"‚úÖ Found news for: {', '.join(found_tickers)}")
        else:
            st.warning("‚ö†Ô∏è No specific ticker mentions found - results may be generic")
        # News is already displayed directly in fetch_news() function

    # Show sources for custom tickers
    if sources:
        st.subheader("üîó News Sources")
        for s in sources:
            title = s.get("title", "(no title)")
            url = s.get("url", "#")
            date = s.get("date", "")
            st.markdown(f"- [{title}]({url}) ({date})")
    else:
        st.info("No news sources found for the entered tickers.")
